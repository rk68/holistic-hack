{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install holisticai scikit-learn pandas numpy matplotlib seaborn jax -q\n",
    "\n",
    "from holisticai.datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from holisticai.bias.metrics import average_odds_diff, equal_opportunity_diff\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "# dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "# split_dataset = dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "# train = split_dataset['train']\n",
    "# test = split_dataset['test']\n",
    "\n",
    "# bank_dataset = load_dataset(\"bank_marketing\", protected_attribute=\"marital\")\n",
    "# split_dataset2 = bank_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "# train2 = split_dataset2['train']\n",
    "# test2 = split_dataset2['test']\n",
    "\n",
    "# wage_dataset = load_dataset(\"mw_small\", protected_attribute=\"race\")\n",
    "# split_dataset3 = wage_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "# train3 = split_dataset3['train']\n",
    "# test3 = split_dataset3['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Pruning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "# from holisticai.bias.metrics import average_odds_diff\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "class PrePruneDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, fairness_weight=0.5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.fairness_weight = fairness_weight\n",
    "        self.tree_ = None\n",
    "\n",
    "    def _calculate_fairness_deviation(self, group_a, group_b, y_pred, y_true):\n",
    "        \"\"\"Safe calculation of fairness deviation with error handling\"\"\"\n",
    "\n",
    "       # NOTE: the odds diff and equal opportunity diff are 0 a lot\n",
    "        deviation =  1.0 - np.mean(\n",
    "            [\n",
    "                np.abs(average_odds_diff(group_a, group_b, y_pred, y_true)+1e-6),\n",
    "                np.abs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)+1e-6)\n",
    "            ]\n",
    "        )\n",
    "        return deviation\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, groups, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0, float('inf')\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        # Calculate fairness metrics safely\n",
    "        group_a_left = groups[left_idxs] == 0\n",
    "        group_b_left = groups[left_idxs] == 1\n",
    "        group_a_right = groups[right_idxs] == 0\n",
    "        group_b_right = groups[right_idxs] == 1\n",
    "\n",
    "        # Use the most common label in each split as the prediction\n",
    "        y_pred_left = np.full_like(y[left_idxs], self._most_common_label(y[left_idxs]))\n",
    "        y_pred_right = np.full_like(y[right_idxs], self._most_common_label(y[right_idxs]))\n",
    "\n",
    "        # Calculate fairness deviations safely\n",
    "        fairness_deviation_left = self._calculate_fairness_deviation(\n",
    "            group_a_left, group_b_left, y_pred_left, y[left_idxs])\n",
    "        fairness_deviation_right = self._calculate_fairness_deviation(\n",
    "            group_a_right, group_b_right, y_pred_right, y[right_idxs])\n",
    "\n",
    "        # Average the fairness deviations\n",
    "        fairness_deviation = (fairness_deviation_left + fairness_deviation_right) / 2\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain, fairness_deviation\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "        self.tree_ = self._grow_tree(X, y, groups, depth=0)\n",
    "\n",
    "    # Rest of the CustomDecisionTreeClassifier methods remain the same...\n",
    "    def _grow_tree(self, X, y, groups, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        if (depth >= self.max_depth or num_samples < self.min_samples_split or len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        best_split = self._find_best_split(X, y, groups)\n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, best_split['feature_idx']], best_split['threshold'])\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth + 1)\n",
    "\n",
    "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "\n",
    "    def _find_best_split(self, X, y, groups):\n",
    "        num_samples, num_features = X.shape\n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain, fairness_deviation = self._calculate_information_gain(X, y, groups, feature_idx, threshold)\n",
    "                \n",
    "                fairness_penalty = self.fairness_weight * fairness_deviation\n",
    "                #print(f\"fairness pen: {fairness_penalty}, fairness deviation: {fairness_deviation}\")\n",
    "                adjusted_gain = gain - fairness_penalty\n",
    "\n",
    "                if adjusted_gain > best_gain:\n",
    "                    best_gain = adjusted_gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain != -float('inf') else None\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return np.array([self._traverse_tree(x, self.tree_) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "\n",
    "class PrePruneRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, fairness_weight=0.5, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.fairness_weight = fairness_weight\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            group_sample = groups[idxs]\n",
    "\n",
    "            tree = PrePruneDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                fairness_weight=self.fairness_weight\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample, group_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting codecarbon\n",
      "  Downloading codecarbon-2.7.4-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting arrow (from codecarbon)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting click (from codecarbon)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fief-client[cli] (from codecarbon)\n",
      "  Downloading fief_client-0.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pandas in ./holistic-hack/lib/python3.12/site-packages (from codecarbon) (2.2.3)\n",
      "Collecting prometheus-client (from codecarbon)\n",
      "  Downloading prometheus_client-0.21.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: psutil in ./holistic-hack/lib/python3.12/site-packages (from codecarbon) (6.1.0)\n",
      "Collecting py-cpuinfo (from codecarbon)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pynvml (from codecarbon)\n",
      "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting questionary (from codecarbon)\n",
      "  Downloading questionary-2.0.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting rapidfuzz (from codecarbon)\n",
      "  Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in ./holistic-hack/lib/python3.12/site-packages (from codecarbon) (2.32.3)\n",
      "Requirement already satisfied: rich in ./holistic-hack/lib/python3.12/site-packages (from codecarbon) (13.9.4)\n",
      "Collecting typer (from codecarbon)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in ./holistic-hack/lib/python3.12/site-packages (from arrow->codecarbon) (2.9.0.post0)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow->codecarbon)\n",
      "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting httpx<0.28.0,>=0.21.3 (from fief-client[cli]->codecarbon)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jwcrypto<2.0.0,>=1.4 (from fief-client[cli]->codecarbon)\n",
      "  Downloading jwcrypto-1.5.6-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting yaspin (from fief-client[cli]->codecarbon)\n",
      "  Downloading yaspin-3.1.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./holistic-hack/lib/python3.12/site-packages (from pandas->codecarbon) (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./holistic-hack/lib/python3.12/site-packages (from pandas->codecarbon) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./holistic-hack/lib/python3.12/site-packages (from pandas->codecarbon) (2024.2)\n",
      "Collecting prompt_toolkit<=3.0.36,>=2.0 (from questionary->codecarbon)\n",
      "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./holistic-hack/lib/python3.12/site-packages (from requests->codecarbon) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./holistic-hack/lib/python3.12/site-packages (from requests->codecarbon) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./holistic-hack/lib/python3.12/site-packages (from requests->codecarbon) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./holistic-hack/lib/python3.12/site-packages (from requests->codecarbon) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./holistic-hack/lib/python3.12/site-packages (from rich->codecarbon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./holistic-hack/lib/python3.12/site-packages (from rich->codecarbon) (2.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./holistic-hack/lib/python3.12/site-packages (from typer->codecarbon) (4.12.2)\n",
      "Collecting shellingham>=1.3.0 (from typer->codecarbon)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting anyio (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting cryptography>=3.4 (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./holistic-hack/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in ./holistic-hack/lib/python3.12/site-packages (from prompt_toolkit<=3.0.36,>=2.0->questionary->codecarbon) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in ./holistic-hack/lib/python3.12/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
      "Collecting termcolor<2.4.0,>=2.2.0 (from yaspin->fief-client[cli]->codecarbon)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading codecarbon-2.7.4-py3-none-any.whl (504 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading prometheus_client-0.21.0-py3-none-any.whl (54 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
      "Downloading questionary-2.0.1-py3-none-any.whl (34 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jwcrypto-1.5.6-py3-none-any.whl (92 kB)\n",
      "Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
      "Downloading fief_client-0.20.0-py3-none-any.whl (20 kB)\n",
      "Downloading yaspin-3.1.0-py3-none-any.whl (18 kB)\n",
      "Downloading cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: py-cpuinfo, types-python-dateutil, termcolor, sniffio, shellingham, rapidfuzz, pynvml, pycparser, prompt_toolkit, prometheus-client, h11, click, yaspin, questionary, httpcore, cffi, arrow, anyio, typer, httpx, cryptography, jwcrypto, fief-client, codecarbon\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.5.0\n",
      "    Uninstalling termcolor-2.5.0:\n",
      "      Successfully uninstalled termcolor-2.5.0\n",
      "  Attempting uninstall: prompt_toolkit\n",
      "    Found existing installation: prompt_toolkit 3.0.48\n",
      "    Uninstalling prompt_toolkit-3.0.48:\n",
      "      Successfully uninstalled prompt_toolkit-3.0.48\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 8.29.0 requires prompt-toolkit<3.1.0,>=3.0.41, but you have prompt-toolkit 3.0.36 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anyio-4.6.2.post1 arrow-1.3.0 cffi-1.17.1 click-8.1.7 codecarbon-2.7.4 cryptography-43.0.3 fief-client-0.20.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 jwcrypto-1.5.6 prometheus-client-0.21.0 prompt_toolkit-3.0.36 py-cpuinfo-9.0.0 pycparser-2.22 pynvml-11.5.3 questionary-2.0.1 rapidfuzz-3.10.1 shellingham-1.5.4 sniffio-1.3.1 termcolor-2.3.0 typer-0.13.1 types-python-dateutil-2.9.0.20241003 yaspin-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 13:08:16] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 13:08:16] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 13:08:16] No GPU found.\n",
      "[codecarbon INFO @ 13:08:16] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 13:08:16] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Mac OS and ARM processor detected: Please enable PowerMetrics sudo to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 13:08:16] CPU Model on constant consumption mode: Apple M1 Pro\n",
      "[codecarbon INFO @ 13:08:16] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 13:08:16]   Platform system: macOS-15.1-arm64-arm-64bit\n",
      "[codecarbon INFO @ 13:08:16]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 13:08:16]   CodeCarbon version: 2.7.4\n",
      "[codecarbon INFO @ 13:08:16]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 13:08:16]   CPU count: 8\n",
      "[codecarbon INFO @ 13:08:16]   CPU model: Apple M1 Pro\n",
      "[codecarbon INFO @ 13:08:16]   GPU count: None\n",
      "[codecarbon INFO @ 13:08:16]   GPU model: None\n",
      "[codecarbon INFO @ 13:08:17] Saving emissions data to file /Users/rishi/Documents/holistic-hack/emissions.csv\n"
     ]
    }
   ],
   "source": [
    "!pip install codecarbon\n",
    "\n",
    "from codecarbon import EmissionsTracker\n",
    "tracker = EmissionsTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "class Node:\n",
    "    \"\"\"Helper class to store tree node information similar to sklearn's _tree.Tree\"\"\"\n",
    "    def __init__(self, n_node_samples=0, value=None):\n",
    "        self.children_left = -1  # -1 indicates leaf node\n",
    "        self.children_right = -1\n",
    "        self.feature = -2  # -2 indicates uninitialized, -1 for leaf\n",
    "        self.threshold = float('nan')\n",
    "        self.n_node_samples = n_node_samples\n",
    "        self.value = value if value is not None else []\n",
    "        self.label = None  # Added to store the prediction label for leaf nodes\n",
    "\n",
    "class Tree:\n",
    "    \"\"\"Helper class to mimic sklearn's Tree structure\"\"\"\n",
    "    def __init__(self):\n",
    "        self.node_count = 0\n",
    "        self.nodes = []\n",
    "        self.n_classes = []\n",
    "        self.max_depth = 0\n",
    "        \n",
    "    def add_node(self, node):\n",
    "        self.nodes.append(node)\n",
    "        self.node_count += 1\n",
    "        return self.node_count - 1  # Return index of added node\n",
    "\n",
    "class PrePruneDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, fairness_weight=0.5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.fairness_weight = fairness_weight\n",
    "        self.tree_ = None\n",
    "        self._original_tree = None  # Store original tree structure for prediction\n",
    "\n",
    "    def _calculate_fairness_deviation(self, group_a, group_b, y_pred, y_true):\n",
    "        \"\"\"Safe calculation of fairness deviation with error handling\"\"\"\n",
    "        deviation = 1.0 - np.mean([\n",
    "            np.abs(average_odds_diff(group_a, group_b, y_pred, y_true)+1e-6),\n",
    "            np.abs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)+1e-6)\n",
    "        ])\n",
    "        return deviation\n",
    "\n",
    "    def _build_sklearn_tree(self, node, parent_idx=-1, is_left=True):\n",
    "        if not self._sklearn_tree:\n",
    "            self._sklearn_tree = Tree()\n",
    "            \n",
    "        if 'label' in node:\n",
    "            # Leaf node\n",
    "            sklearn_node = Node(\n",
    "                n_node_samples=len(node.get('samples', [])),\n",
    "                value=[[0, 0] if node['label'] == 0 else [0, 1]]\n",
    "            )\n",
    "            sklearn_node.feature = -1  # Indicates leaf\n",
    "            sklearn_node.label = node['label']  # Store the prediction label\n",
    "            node_idx = self._sklearn_tree.add_node(sklearn_node)\n",
    "        else:\n",
    "            # Internal node\n",
    "            sklearn_node = Node(\n",
    "                n_node_samples=len(node.get('samples', [])),\n",
    "                value=[[0, 0]]  # Placeholder, would normally contain class distribution\n",
    "            )\n",
    "            sklearn_node.feature = node['feature_idx']\n",
    "            sklearn_node.threshold = node['threshold']\n",
    "            node_idx = self._sklearn_tree.add_node(sklearn_node)\n",
    "            \n",
    "            # Recursively build left and right subtrees\n",
    "            left_idx = self._build_sklearn_tree(node['left'], node_idx, True)\n",
    "            right_idx = self._build_sklearn_tree(node['right'], node_idx, False)\n",
    "            \n",
    "            # Update parent node with children indices\n",
    "            sklearn_node.children_left = left_idx\n",
    "            sklearn_node.children_right = right_idx\n",
    "        \n",
    "        # Update parent's child index if this isn't the root\n",
    "        if parent_idx >= 0:\n",
    "            parent_node = self._sklearn_tree.nodes[parent_idx]\n",
    "            if is_left:\n",
    "                parent_node.children_left = node_idx\n",
    "            else:\n",
    "                parent_node.children_right = node_idx\n",
    "                \n",
    "        return node_idx\n",
    "    \n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "            \n",
    "        # Store original tree structure\n",
    "        self._original_tree = self._grow_tree(X, y, groups, depth=0)\n",
    "        \n",
    "        # Build sklearn-style tree structure\n",
    "        self._sklearn_tree = None\n",
    "        self._build_sklearn_tree(self._original_tree)\n",
    "        \n",
    "        # Make tree_ attribute point to sklearn-style tree\n",
    "        self.tree_ = self._sklearn_tree\n",
    "\n",
    "\n",
    "    def _traverse_tree_sklearn(self, x, tree, node_id=0):\n",
    "        \"\"\"Traverse the sklearn-style tree structure\"\"\"\n",
    "        node = tree.nodes[node_id]\n",
    "        \n",
    "        if node.feature == -1:  # Leaf node\n",
    "            return node.label\n",
    "            \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree_sklearn(x, tree, node.children_left)\n",
    "        return self._traverse_tree_sklearn(x, tree, node.children_right)\n",
    "\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, groups, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0, float('inf')\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        # Calculate fairness metrics safely\n",
    "        group_a_left = groups[left_idxs] == 0\n",
    "        group_b_left = groups[left_idxs] == 1\n",
    "        group_a_right = groups[right_idxs] == 0\n",
    "        group_b_right = groups[right_idxs] == 1\n",
    "\n",
    "        # Use the most common label in each split as the prediction\n",
    "        y_pred_left = np.full_like(y[left_idxs], self._most_common_label(y[left_idxs]))\n",
    "        y_pred_right = np.full_like(y[right_idxs], self._most_common_label(y[right_idxs]))\n",
    "\n",
    "        # Calculate fairness deviations safely\n",
    "        fairness_deviation_left = self._calculate_fairness_deviation(\n",
    "            group_a_left, group_b_left, y_pred_left, y[left_idxs])\n",
    "        fairness_deviation_right = self._calculate_fairness_deviation(\n",
    "            group_a_right, group_b_right, y_pred_right, y[right_idxs])\n",
    "\n",
    "        # Average the fairness deviations\n",
    "        fairness_deviation = (fairness_deviation_left + fairness_deviation_right) / 2\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain, fairness_deviation\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the sklearn-style tree structure\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return np.array([self._traverse_tree_sklearn(x, self.tree_) for x in X])\n",
    "\n",
    "    def _grow_tree(self, X, y, groups, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        if (depth >= self.max_depth or num_samples < self.min_samples_split or len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y), 'num_samples': num_samples, 'depth': depth}\n",
    "\n",
    "        best_split = self._find_best_split(X, y, groups)\n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y), 'num_samples': num_samples, 'depth': depth}\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, best_split['feature_idx']], best_split['threshold'])\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth + 1)\n",
    "\n",
    "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
    "                'left': left_subtree, 'right': right_subtree, 'num_samples': num_samples, 'depth': depth}\n",
    "\n",
    "\n",
    "    # [Rest of the methods remain the same...]\n",
    "    def compute_weighted_average_depth(self):\n",
    "        if not self.tree_:\n",
    "            return 0\n",
    "\n",
    "        total_depth = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        def traverse(node):\n",
    "            nonlocal total_depth, total_samples\n",
    "            if 'label' in node:\n",
    "                # Leaf node\n",
    "                total_depth += node['depth'] * node['num_samples']\n",
    "                total_samples += node['num_samples']\n",
    "                return\n",
    "\n",
    "            # Traverse left and right subtrees\n",
    "            traverse(node['left'])\n",
    "            traverse(node['right'])\n",
    "\n",
    "        traverse(self.tree_)\n",
    "        return total_depth / total_samples if total_samples != 0 else 0\n",
    "\n",
    "    def _find_best_split(self, X, y, groups):\n",
    "        num_samples, num_features = X.shape\n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain, fairness_deviation = self._calculate_information_gain(X, y, groups, feature_idx, threshold)\n",
    "                \n",
    "                fairness_penalty = self.fairness_weight * fairness_deviation\n",
    "                #print(f\"fairness pen: {fairness_penalty}, fairness deviation: {fairness_deviation}\")\n",
    "                adjusted_gain = gain - fairness_penalty\n",
    "\n",
    "                if adjusted_gain > best_gain:\n",
    "                    best_gain = adjusted_gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain != -float('inf') else None\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "    \n",
    "    def tree_depth(self):\n",
    "        \"\"\"Compute the depth of the tree.\"\"\"\n",
    "        return self._compute_depth(self.tree_)\n",
    "\n",
    "    def _compute_depth(self, node):\n",
    "        if isinstance(node, dict) and 'label' in node:\n",
    "            return 0\n",
    "        left_depth = self._compute_depth(node['left']) if isinstance(node, dict) and 'left' in node else 0\n",
    "        right_depth = self._compute_depth(node['right']) if isinstance(node, dict) and 'right' in node else 0\n",
    "        return 1 + max(left_depth, right_depth)\n",
    "\n",
    "\n",
    "\n",
    "class PrePruneRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, fairness_weight=0.5, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.fairness_weight = fairness_weight\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            group_sample = groups[idxs]\n",
    "\n",
    "            tree = PrePruneDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                fairness_weight=self.fairness_weight\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample, group_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "    \n",
    "    def average_tree_depth(self):\n",
    "        \"\"\"\n",
    "        Compute the average depth of all trees in the forest.\n",
    "        \"\"\"\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"The forest has not been trained yet. Please fit the model first.\")\n",
    "        \n",
    "        total_depth = sum(tree.tree_depth() for tree in self.trees)\n",
    "        return total_depth / len(self.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:06:00] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:06:00] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:06:00] No GPU found.\n",
      "[codecarbon INFO @ 15:06:00] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 15:06:00] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Mac OS and ARM processor detected: Please enable PowerMetrics sudo to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 15:06:00] CPU Model on constant consumption mode: Apple M1 Pro\n",
      "[codecarbon INFO @ 15:06:00] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:06:00]   Platform system: macOS-15.1-arm64-arm-64bit\n",
      "[codecarbon INFO @ 15:06:00]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 15:06:00]   CodeCarbon version: 2.7.4\n",
      "[codecarbon INFO @ 15:06:00]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:06:00]   CPU count: 8\n",
      "[codecarbon INFO @ 15:06:00]   CPU model: Apple M1 Pro\n",
      "[codecarbon INFO @ 15:06:00]   GPU count: None\n",
      "[codecarbon INFO @ 15:06:00]   GPU model: None\n",
      "[codecarbon INFO @ 15:06:01] Saving emissions data to file /Users/rishi/Documents/holistic-hack/emissions.csv\n",
      "[codecarbon INFO @ 15:06:16] Energy consumed for RAM : 0.000025 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:06:16] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:06:16] 0.000046 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:06:31] Energy consumed for RAM : 0.000050 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:06:31] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:06:31] 0.000092 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:06:46] Energy consumed for RAM : 0.000075 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:06:46] Energy consumed for all CPUs : 0.000063 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:06:46] 0.000138 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:07:01] Energy consumed for RAM : 0.000100 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:07:01] Energy consumed for all CPUs : 0.000083 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:07:01] 0.000183 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:07:16] Energy consumed for RAM : 0.000125 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:07:16] Energy consumed for all CPUs : 0.000104 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:07:16] 0.000229 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:07:31] Energy consumed for RAM : 0.000150 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:07:31] Energy consumed for all CPUs : 0.000125 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:07:31] 0.000275 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:07:46] Energy consumed for RAM : 0.000175 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:07:46] Energy consumed for all CPUs : 0.000146 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:07:46] 0.000321 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:08:01] Energy consumed for RAM : 0.000200 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:08:01] Energy consumed for all CPUs : 0.000167 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:08:01] 0.000367 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:08:01] 0.000725 g.CO2eq/s mean an estimation of 22.877270565398764 kg.CO2eq/year\n",
      "[codecarbon INFO @ 15:08:02] Energy consumed for RAM : 0.000203 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:08:02] Energy consumed for all CPUs : 0.000169 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 15:08:02] 0.000372 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total carbon emissions during training: 0.0001 kg CO2eq\n",
      "accuracy 0.6550607287449393\n",
      "equal opportunity diff -0.00521607691545245\n",
      "average odds diff -0.0657650549769987\n",
      "Average tree depth in the random forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "# Example usage\n",
    "X = compas_train['X']\n",
    "y = compas_train['y']\n",
    "groups = np.where(compas_train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "\n",
    "# Create and fit the model\n",
    "pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    fairness_weight=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the emissions tracker\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "pre_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Stop the tracker and get emissions\n",
    "emissions = tracker.stop()\n",
    "\n",
    "# Output total emissions\n",
    "print(f\"Total carbon emissions during training: {emissions:.4f} kg CO2eq\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = pre_prune_clf.predict(compas_test['X'])\n",
    "\n",
    "# Compute accuracy\n",
    "print(\"accuracy\", np.count_nonzero(predictions == compas_test['y']) / len(compas_test['y']))\n",
    "\n",
    "# Compute fairness metrics\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(compas_test['group_a'], compas_test['group_b'], predictions, compas_test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(compas_test['group_a'], compas_test['group_b'], predictions, compas_test['y']))\n",
    "\n",
    "# Compute average tree depth\n",
    "average_depth = pre_prune_clf.average_tree_depth()\n",
    "print(\"Average tree depth in the random forest:\", average_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6550607287449393\n",
      "equal opportunity diff -0.00521607691545245\n",
      "average odds diff -0.0657650549769987\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PrePruneRandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39maverage odds diff\u001b[39m\u001b[39m\"\u001b[39m, average_odds_diff(compas_test[\u001b[39m'\u001b[39m\u001b[39mgroup_a\u001b[39m\u001b[39m'\u001b[39m], compas_test[\u001b[39m'\u001b[39m\u001b[39mgroup_b\u001b[39m\u001b[39m'\u001b[39m], predictions, compas_test[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mholisticai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexplainability\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m weighted_average_depth\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m weighted_avg_depth \u001b[39m=\u001b[39m weighted_average_depth(pre_prune_clf\u001b[39m.\u001b[39;49mtree_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeighted Average Depth: \u001b[39m\u001b[39m{\u001b[39;00mweighted_avg_depth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrePruneRandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = compas_train['X']\n",
    "y = compas_train['y']\n",
    "groups = np.where(compas_train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "# Create and fit the model\n",
    "pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    fairness_weight=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "pre_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pre_prune_clf.predict(compas_test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == compas_test['y'])/len(compas_test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(compas_test['group_a'], compas_test['group_b'], predictions, compas_test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(compas_test['group_a'], compas_test['group_b'], predictions, compas_test['y']))\n",
    "\n",
    "from holisticai.explainability.metrics import weighted_average_depth\n",
    "weighted_avg_depth = weighted_average_depth(pre_prune_clf.tree_)\n",
    "print(f\"Weighted Average Depth: {weighted_avg_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrePruneRandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     traverse(model\u001b[39m.\u001b[39mtree_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m total_depth \u001b[39m/\u001b[39m total_samples \u001b[39mif\u001b[39;00m total_samples \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m weighted_avg_depth \u001b[39m=\u001b[39m compute_weighted_average_depth(pre_prune_clf)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeighted Average Depth: \u001b[39m\u001b[39m{\u001b[39;00mweighted_avg_depth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_weighted_average_depth\u001b[39m(model):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39;49mtree_:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     total_depth \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrePruneRandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_weighted_average_depth(model):\n",
    "    if not model.tree_:\n",
    "        return 0\n",
    "\n",
    "    total_depth = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    def traverse(node):\n",
    "        nonlocal total_depth, total_samples\n",
    "        if 'label' in node:\n",
    "            # Leaf node\n",
    "            total_depth += node['depth'] * node['num_samples']\n",
    "            total_samples += node['num_samples']\n",
    "            return\n",
    "\n",
    "        # Traverse left and right subtrees\n",
    "        traverse(node['left'])\n",
    "        traverse(node['right'])\n",
    "\n",
    "    traverse(model.tree_)\n",
    "    return total_depth / total_samples if total_samples != 0 else 0\n",
    "\n",
    "weighted_avg_depth = compute_weighted_average_depth(pre_prune_clf)\n",
    "print(f\"Weighted Average Depth: {weighted_avg_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrePruneRandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weighted_average_explainability_score(pre_prune_clf\u001b[39m.\u001b[39;49mtree_)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrePruneRandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "weighted_average_explainability_score(pre_prune_clf.tree_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrePruneRandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m total_score\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Calculate the weighted average explainability score using clf.tree_\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m explainability_score \u001b[39m=\u001b[39m weighted_average_explainability_score(pre_prune_clf\u001b[39m.\u001b[39;49mtree_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeighted Average Explainability Score:\u001b[39m\u001b[39m\"\u001b[39m, explainability_score)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrePruneRandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "def weighted_average_explainability_score(tree):\n",
    "    # This function will traverse the tree and compute an explainability score.\n",
    "    \n",
    "    def traverse_and_score(node, depth=0):\n",
    "        # If the node is a leaf, return its contribution to explainability\n",
    "        if 'label' in node:\n",
    "            return 1 / (depth + 1)  # The deeper the leaf, the lower the score (more complex path)\n",
    "        \n",
    "        # If the node is internal, traverse the left and right branches\n",
    "        left_score = traverse_and_score(node['left'], depth + 1)\n",
    "        right_score = traverse_and_score(node['right'], depth + 1)\n",
    "        \n",
    "        # The score contribution of this node will be influenced by its depth and both branches\n",
    "        return (left_score + right_score) / 2\n",
    "    \n",
    "    # Start traversal from the root node\n",
    "    total_score = traverse_and_score(tree)\n",
    "    return total_score\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Calculate the weighted average explainability score using clf.tree_\n",
    "explainability_score = weighted_average_explainability_score(pre_prune_clf.tree_)\n",
    "print(\"Weighted Average Explainability Score:\", explainability_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 0 does not have a valid tree_ structure.\n",
      "Tree 1 does not have a valid tree_ structure.\n",
      "Tree 2 does not have a valid tree_ structure.\n",
      "Tree 3 does not have a valid tree_ structure.\n",
      "Tree 4 does not have a valid tree_ structure.\n",
      "No valid explainability scores were computed.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each tree and calculate the explainability score\n",
    "explainability_scores = []\n",
    "for idx, tree in enumerate(pre_prune_clf.trees):\n",
    "    try:\n",
    "        score = weighted_average_explainability_score(tree.tree_)\n",
    "        explainability_scores.append(score)\n",
    "    except AttributeError:\n",
    "        print(f\"Tree {idx} does not have a valid tree_ structure.\")\n",
    "\n",
    "# Compute the average explainability score across all trees\n",
    "if explainability_scores:\n",
    "    avg_explainability_score = np.mean(explainability_scores)\n",
    "    print(\"Weighted Average Explainability Score:\", avg_explainability_score)\n",
    "else:\n",
    "    print(\"No valid explainability scores were computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6550607287449393\n",
      "equal opportunity diff -0.00521607691545245\n",
      "average odds diff -0.0657650549769987\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. why is fairness deviation = 0\n",
    "# 2. Add terms for race and gender bias (?) + model needs to trade off\n",
    "# 3. Fix hyperparmaeter optimization to get the best model + scores]\n",
    "\n",
    "\n",
    "# Limitation: protected characterstic needs to be binary \n",
    "# Extension: pairwise bias and how to mitigate that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Pruning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from holisticai.bias.metrics import average_odds_diff\n",
    "\n",
    "class PostPruneDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, verbose=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        self.tree_ = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        if (depth >= self.max_depth or num_samples < self.min_samples_split or len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        \n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, best_split['feature_idx']], best_split['threshold'])\n",
    "\n",
    "        # If either split is empty, return the most common label\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
    "\n",
    "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._calculate_information_gain(X, y, feature_idx, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain != -float('inf') else None\n",
    "    \n",
    "\n",
    "    def _calculate_fairness_deviation(self, group_a, group_b, y_pred, y_true):\n",
    "        \"\"\"Safe calculation of fairness deviation with error handling\"\"\"\n",
    "\n",
    "       # NOTE: the odds diff and equal opportunity diff are 0 a lot\n",
    "        deviation =  1.0 - np.mean(\n",
    "            [\n",
    "                np.abs(average_odds_diff(group_a, group_b, y_pred, y_true)+1e-6),\n",
    "                np.abs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)+1e-6)\n",
    "            ]\n",
    "        )\n",
    "        return deviation\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0  # Default to label 0 if y is empty\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return np.array([self._traverse_tree(x, self.tree_) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "\n",
    "    def prune_for_fairness_and_accuracy(self, X, y, groups):\n",
    "        \"\"\"\n",
    "        Post-training pruning to improve fairness and maintain accuracy.\n",
    "        Start pruning from the leaves to avoid removing too much of the tree at once.\n",
    "        \"\"\"\n",
    "        group_a = np.where(groups == 1, 1, 0)\n",
    "        group_b = np.where(groups == 0, 1, 0)\n",
    "        initial_leaves_count = self._count_leaves(self.tree_)\n",
    "        initial_fairness = self._calculate_fairness_deviation(group_a, group_b, self.predict(X), y)#1 - average_odds_diff(group_a, group_b, self.predict(X), y)\n",
    "        initial_accuracy = accuracy_score(y, self.predict(X))\n",
    "\n",
    "        self._prune_tree(self.tree_, X, y, groups)\n",
    "\n",
    "        final_leaves_count = self._count_leaves(self.tree_)\n",
    "        final_fairness = self._calculate_fairness_deviation(group_a, group_b, self.predict(X), y) #1 - average_odds_diff(groups, groups, self.predict(X), y)\n",
    "        final_accuracy = accuracy_score(y, self.predict(X))\n",
    "        if self.verbose == True:\n",
    "            print(f\"Initial number of leaves: {initial_leaves_count}\")\n",
    "            print(f\"Final number of leaves: {final_leaves_count}\")\n",
    "            print(f\"Difference in number of leaves: {initial_leaves_count - final_leaves_count}\")\n",
    "            print(f\"Fairness before pruning: {initial_fairness}\")\n",
    "            print(f\"Fairness after pruning: {final_fairness}\")\n",
    "            print(f\"Difference in fairness: {final_fairness - initial_fairness}\")\n",
    "            print(f\"Accuracy before pruning: {initial_accuracy}\")\n",
    "            print(f\"Accuracy after pruning: {final_accuracy}\")\n",
    "            print(f\"Difference in accuracy: {final_accuracy - initial_accuracy}\")\n",
    "\n",
    "    def _prune_tree(self, node, X, y, groups):\n",
    "        if 'label' in node:\n",
    "            return\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, node['feature_idx']], node['threshold'])\n",
    "        \n",
    "        # Check if split produces empty nodes\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            node.clear()\n",
    "            node['label'] = self._most_common_label(y)\n",
    "            return\n",
    "\n",
    "        # Recursively prune left and right subtrees first (bottom-up approach)\n",
    "        self._prune_tree(node['left'], X[left_idxs], y[left_idxs], groups[left_idxs])\n",
    "        self._prune_tree(node['right'], X[right_idxs], y[right_idxs], groups[right_idxs])\n",
    "\n",
    "        # Only consider pruning if both children are leaves\n",
    "        if 'label' not in node['left'] or 'label' not in node['right']:\n",
    "            return\n",
    "\n",
    "        # Calculate metrics before pruning\n",
    "        group_a = np.where(groups == 1, 1, 0)\n",
    "        group_b = np.where(groups == 0, 1, 0)\n",
    "\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy_before = accuracy_score(y, y_pred)\n",
    "\n",
    "        fairness_before = self._calculate_fairness_deviation(group_a, group_b, y_pred, y)#1 - average_odds_diff(group_a, group_b, y_pred, y)\n",
    "\n",
    "\n",
    "        # Temporarily prune the node\n",
    "        original_node = node.copy()\n",
    "        node.clear()\n",
    "        node['label'] = self._most_common_label(y)\n",
    "\n",
    "        # Calculate metrics after pruning\n",
    "        y_pred_pruned = self.predict(X)\n",
    "        accuracy_after = accuracy_score(y, y_pred_pruned)\n",
    "        fairness_after = self._calculate_fairness_deviation(group_a, group_b, y_pred_pruned, y)#1 - average_odds_diff(group_a, group_b, y_pred_pruned, y)\n",
    "\n",
    "        # Define minimum acceptable changes\n",
    "        MIN_ACCURACY_DROP = 0.05  # Allow maximum 2% accuracy drop\n",
    "        MIN_FAIRNESS_IMPROVEMENT = 0.025  # Require at least 5% fairness improvement\n",
    "\n",
    "        # Restore the node if:\n",
    "        # 1. Accuracy drops more than threshold OR\n",
    "        # 2. Fairness doesn't improve enough\n",
    "        if (accuracy_before - accuracy_after > MIN_ACCURACY_DROP or \n",
    "            fairness_after - fairness_before < MIN_FAIRNESS_IMPROVEMENT):\n",
    "            node.clear()\n",
    "            node.update(original_node)\n",
    "        \n",
    "    def _count_leaves(self, node):\n",
    "        if 'label' in node:\n",
    "            return 1\n",
    "        return self._count_leaves(node['left']) + self._count_leaves(node['right'])\n",
    "\n",
    "\n",
    "    def tree_depth(self):\n",
    "        \"\"\"Compute the depth of the tree.\"\"\"\n",
    "        return self._compute_depth(self.tree_)\n",
    "\n",
    "    def _compute_depth(self, node):\n",
    "        if isinstance(node, dict) and 'label' in node:\n",
    "            return 0\n",
    "        left_depth = self._compute_depth(node['left']) if isinstance(node, dict) and 'left' in node else 0\n",
    "        right_depth = self._compute_depth(node['right']) if isinstance(node, dict) and 'right' in node else 0\n",
    "        return 1 + max(left_depth, right_depth)\n",
    "\n",
    "\n",
    "class PostPruneRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            group_sample = groups[idxs]\n",
    "\n",
    "            tree = PostPruneDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            tree.prune_for_fairness_and_accuracy(X_sample, y_sample, group_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "\n",
    "    def average_tree_depth(self):\n",
    "        \"\"\"\n",
    "        Compute the average depth of all trees in the forest.\n",
    "        \"\"\"\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"The forest has not been trained yet. Please fit the model first.\")\n",
    "        \n",
    "        total_depth = sum(tree.tree_depth() for tree in self.trees)\n",
    "        return total_depth / len(self.trees)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tree depth in the post-pruned random forest: 27.4\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = compas_train['X']\n",
    "y = compas_train['y']\n",
    "groups = np.where(compas_train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "\n",
    "# Create and fit the model\n",
    "post_prune_clf = PostPruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=50,\n",
    "    random_state=42\n",
    ")\n",
    "post_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = post_prune_clf.predict(compas_test['X'])\n",
    "\n",
    "# Compute average tree depth\n",
    "post_average_depth = post_prune_clf.average_tree_depth()\n",
    "print(\"Average tree depth in the post-pruned random forest:\", post_average_depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.637246963562753\n",
      "equal opportunity diff -0.02783972643473087\n",
      "average odds diff -0.08915048942413048\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", np.count_nonzero(predictions == compas_test['y'])/len(compas_test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(compas_test['group_a'], compas_test['group_b'], predictions, compas_test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(compas_test['group_a'], compas_test['group_b'], predictions, compas_test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "class BaselineDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if len(y) == 0:\n",
    "            raise ValueError(\"Cannot train on empty dataset\")\n",
    "        self.tree_ = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        \n",
    "        # Check for empty arrays\n",
    "        if num_samples == 0:\n",
    "            return {'label': 0}  # Default label for empty node\n",
    "            \n",
    "        if (depth >= self.max_depth or \n",
    "            num_samples < self.min_samples_split or \n",
    "            len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        feature_idx = best_split['feature_idx']\n",
    "        threshold = best_split['threshold']\n",
    "        \n",
    "        # Get the split indices\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        \n",
    "        # Check if split is valid\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'feature_idx': feature_idx,\n",
    "            'threshold': threshold,\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree\n",
    "        }\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        if num_samples < 2:  # Need at least 2 samples to split\n",
    "            return None\n",
    "            \n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._calculate_information_gain(X, y, feature_idx, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain > -float('inf') else None\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return -float('inf')\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0  # Default label for empty array\n",
    "        counter = Counter(y)\n",
    "        if not counter:\n",
    "            return 0  # Default label for empty counter\n",
    "        return counter.most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if not self.tree_:\n",
    "            raise ValueError(\"Tree not fitted. Call fit() first.\")\n",
    "        return np.array([self._traverse_tree(x, self.tree_) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "    \n",
    "\n",
    "    def tree_depth(self):\n",
    "        \"\"\"Compute the depth of the tree.\"\"\"\n",
    "        return self._compute_depth(self.tree_)\n",
    "\n",
    "    def _compute_depth(self, node):\n",
    "        if isinstance(node, dict) and 'label' in node:\n",
    "            return 0\n",
    "        left_depth = self._compute_depth(node['left']) if isinstance(node, dict) and 'left' in node else 0\n",
    "        right_depth = self._compute_depth(node['right']) if isinstance(node, dict) and 'right' in node else 0\n",
    "        return 1 + max(left_depth, right_depth)\n",
    "\n",
    "\n",
    "\n",
    "class BaselineRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if len(y) == 0:\n",
    "            raise ValueError(\"Cannot train on empty dataset\")\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "\n",
    "            tree = BaselineDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "\n",
    "    def average_tree_depth(self):\n",
    "        \"\"\"\n",
    "        Compute the average depth of all trees in the forest.\n",
    "        \"\"\"\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"The forest has not been trained yet. Please fit the model first.\")\n",
    "        \n",
    "        total_depth = sum(tree.tree_depth() for tree in self.trees)\n",
    "        return total_depth / len(self.trees)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6502024291497975\n",
      "equal opportunity diff -0.05227227673704038\n",
      "average odds diff -0.10671824606559538\n",
      "Average tree depth in the post-pruned random forest: 16.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "def get_results(train_set, test_set):\n",
    "    X = train_set['X']\n",
    "    y = train_set['y']\n",
    "\n",
    "    # Create and fit the model\n",
    "    baseline_clf = BaselineRandomForestClassifier(\n",
    "        n_estimators=5,\n",
    "        max_depth=16,\n",
    "        random_state=42\n",
    "    )\n",
    "    baseline_clf.fit(X, y)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = baseline_clf.predict(test_set['X'])\n",
    "\n",
    "    print(\"accuracy\", np.count_nonzero(predictions == test_set['y'])/len(test_set['y']))\n",
    "    print(\"equal opportunity diff\", equal_opportunity_diff(test_set['group_a'], test_set['group_b'], predictions, test_set['y']))\n",
    "    print(\"average odds diff\", average_odds_diff(test_set['group_a'], test_set['group_b'], predictions, test_set['y']))\n",
    "\n",
    "    # Compute average tree depth\n",
    "    baseline_average_depth = baseline_clf.average_tree_depth()\n",
    "    print(\"Average tree depth in the post-pruned random forest:\", baseline_average_depth)\n",
    "\n",
    "\n",
    "get_results(compas_train, compas_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.938\n",
      "equal opportunity diff -0.01157299722371985\n",
      "average odds diff -0.0640901519704925\n"
     ]
    }
   ],
   "source": [
    "get_results(wage_train, wage_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load the datasets\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m compas_dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mcompas_two_year_recid\u001b[39m\u001b[39m\"\u001b[39m, protected_attribute\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m compas_split_dataset \u001b[39m=\u001b[39m compas_dataset\u001b[39m.\u001b[39mtrain_test_split(test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m compas_train \u001b[39m=\u001b[39m compas_split_dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# load the datasets\n",
    "\n",
    "compas_dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "compas_split_dataset = compas_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "compas_train = compas_split_dataset['train']\n",
    "compas_test = compas_split_dataset['test']\n",
    "\n",
    "bank_dataset = load_dataset(\"bank_marketing\", protected_attribute=\"marital\")\n",
    "bank_split_dataset = bank_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "bank_train = bank_split_dataset['train']\n",
    "bank_test = bank_split_dataset['test']\n",
    "\n",
    "wage_dataset = load_dataset(\"mw_small\", protected_attribute=\"race\")\n",
    "wage_split_dataset = wage_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "wage_train = wage_split_dataset['train']\n",
    "wage_test = wage_split_dataset['test']\n",
    "\n",
    "compas_groups = np.where(compas_train['p_attrs']['sex'].to_numpy() == 'Male', 1, 0)\n",
    "bank_groups = np.where(bank_train['p_attrs']['marital'].to_numpy() == 1, 1, 0)\n",
    "wage_groups = np.where(wage_train['p_attrs'][\"race\"].to_numpy() == \"White\", 1, 0)\n",
    "\n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "\n",
    "# Create and fit the model\n",
    "baseline_clf = BaselineRandomForestClassifier(\n",
    "    n_estimators=3,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "baseline_clf.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = baseline_clf.predict(test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "\n",
    "\n",
    "pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    fairness_weight=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "pre_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pre_prune_clf.predict(test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "\n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "\n",
    "# Create and fit the model\n",
    "post_prune_clf = PostPruneRandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=50,\n",
    "    random_state=42\n",
    ")\n",
    "post_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = post_prune_clf.predict(test['X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "compas_dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "compas_split_dataset = compas_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "compas_train = compas_split_dataset['train']\n",
    "compas_test = compas_split_dataset['test']\n",
    "\n",
    "bank_dataset = load_dataset(\"bank_marketing\", protected_attribute=\"marital\")\n",
    "bank_split_dataset = bank_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "bank_train = bank_split_dataset['train']\n",
    "bank_test = bank_split_dataset['test']\n",
    "\n",
    "wage_dataset = load_dataset(\"mw_small\", protected_attribute=\"race\")\n",
    "wage_split_dataset = wage_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "wage_train = wage_split_dataset['train']\n",
    "wage_test = wage_split_dataset['test']\n",
    "\n",
    "# Define groups for each dataset\n",
    "compas_groups_train = np.where(compas_train['p_attrs']['sex'].to_numpy() == 'Male', 1, 0)\n",
    "compas_groups_test = np.where(compas_test['p_attrs']['sex'].to_numpy() == 'Male', 1, 0)\n",
    "\n",
    "bank_groups_train = np.where(bank_train['p_attrs']['marital'].to_numpy() == 1, 1, 0)\n",
    "bank_groups_test = np.where(bank_test['p_attrs']['marital'].to_numpy() == 1, 1, 0)\n",
    "\n",
    "wage_groups_train = np.where(wage_train['p_attrs']['race'].to_numpy() == \"White\", 1, 0)\n",
    "wage_groups_test = np.where(wage_test['p_attrs']['race'].to_numpy() == \"White\", 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.648582995951417\n",
      "equal opportunity diff -0.05603875507978995\n",
      "average odds diff -0.10860148523697016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_results_post(train, test, groups):\n",
    "    # Example usage\n",
    "    X = train['X']\n",
    "    y = train['y']\n",
    "    #groups = np.where(train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "\n",
    "    # Create and fit the model\n",
    "    post_prune_clf = PostPruneRandomForestClassifier(\n",
    "        n_estimators=5,\n",
    "        max_depth=16,\n",
    "        random_state=42\n",
    "    )\n",
    "    post_prune_clf.fit(X, y, groups)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = post_prune_clf.predict(test['X'])\n",
    "    print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "    print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "    print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "\n",
    "\n",
    "get_results_post(compas_train, compas_test, compas_groups_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.938\n",
      "equal opportunity diff -0.011390914193858181\n",
      "average odds diff -0.06002925183074248\n"
     ]
    }
   ],
   "source": [
    "get_results_post(wage_train, wage_test, wage_groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8942828707287405\n",
      "equal opportunity diff 0.004921584282305824\n",
      "average odds diff -0.021952119592195396\n"
     ]
    }
   ],
   "source": [
    "get_results_post(bank_train, bank_test, bank_groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6550607287449393\n",
      "equal opportunity diff -0.00521607691545245\n",
      "average odds diff -0.0657650549769987\n"
     ]
    }
   ],
   "source": [
    "def get_results_pre(train, test, groups):\n",
    "\n",
    "    # Example usage\n",
    "    X = train['X']\n",
    "    y = train['y']\n",
    "    #groups = np.where(train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "    # Create and fit the model\n",
    "    pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "        n_estimators=5,\n",
    "        max_depth=16,\n",
    "        fairness_weight=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    pre_prune_clf.fit(X, y, groups)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = pre_prune_clf.predict(test['X'])\n",
    "\n",
    "    print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "    print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "    print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "    return pre_prune_clf, predictions\n",
    "\n",
    "pp_clf, preds = get_results_pre(compas_train, compas_test, compas_groups_train)\n",
    "\n",
    "#get_results_pre(compas_train, compas_test, compas_groups_train)\n",
    "#get_results_pre(wage_train, wage_train, wage_groups_train)\n",
    "#get_results_pre(bank_train, bank_test, bank_groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrePruneRandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mholisticai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexplainability\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m weighted_average_depth, tree_depth_variance, weighted_average_depth, weighted_average_explainability_score\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tree_depth_variance(pp_clf\u001b[39m.\u001b[39;49mtree_)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrePruneRandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "from holisticai.explainability.metrics import weighted_average_depth, tree_depth_variance, weighted_average_depth, weighted_average_explainability_score\n",
    "\n",
    "tree_depth_variance(pp_clf.tree_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'BaselineRandomForestClassifier', 'dataset': 'COMPAS', 'accuracy': 0.6518218623481782, 'equal_opportunity_diff': np.float64(-0.059706115571414364), 'average_odds_diff': np.float64(-0.11079272549327074)}, {'model': 'PrePruneRandomForestClassifier', 'dataset': 'COMPAS', 'accuracy': 0.6526315789473685, 'equal_opportunity_diff': np.float64(-0.05212359996035276), 'average_odds_diff': np.float64(-0.09738310340560127)}, {'model': 'PostPruneRandomForestClassifier', 'dataset': 'COMPAS', 'accuracy': 0.6477732793522267, 'equal_opportunity_diff': np.float64(-0.06630984240261673), 'average_odds_diff': np.float64(-0.11076928081132958)}, {'model': 'BaselineRandomForestClassifier', 'dataset': 'Bank Marketing', 'accuracy': 0.8993696782041358, 'equal_opportunity_diff': np.float64(0.005837640478291495), 'average_odds_diff': np.float64(-0.017994007323841765)}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_and_evaluate_models(bank_train, bank_test, bank_groups_train, bank_groups_test, \u001b[39m\"\u001b[39;49m\u001b[39mBank Marketing\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(results)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#train_and_evaluate_models(wage_train, wage_test, wage_groups_train, wage_groups_test, \"Wage\")\u001b[39;00m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train and evaluate BaselineRandomForestClassifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m baseline_clf \u001b[39m=\u001b[39m BaselineRandomForestClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m baseline_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m predictions \u001b[39m=\u001b[39m baseline_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m results\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mBaselineRandomForestClassifier\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m: dataset_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39maverage_odds_diff\u001b[39m\u001b[39m'\u001b[39m: average_odds_diff(groups_test, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m groups_test, predictions, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m })\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m X_sample, y_sample \u001b[39m=\u001b[39m X[idxs], y[idxs]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m tree \u001b[39m=\u001b[39m BaselineDecisionTreeClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m     min_samples_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_sample, y_sample)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot train on empty dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X, y, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(left_idxs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(right_idxs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: feature_idx,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(left_idxs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(right_idxs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: feature_idx,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: feature_idx,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: feature_idx,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(left_idxs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(right_idxs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: feature_idx,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m }\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m (depth \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39mor\u001b[39;00m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     num_samples \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split \u001b[39mor\u001b[39;00m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_best_split(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m best_split:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m thresholds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(X[:, feature_idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m thresholds:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_information_gain(X, y, feature_idx, threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39mif\u001b[39;00m gain \u001b[39m>\u001b[39m best_gain:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         best_gain \u001b[39m=\u001b[39m gain\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m n_left, n_right \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(left_idxs), \u001b[39mlen\u001b[39m(right_idxs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m entropy_left, entropy_right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_entropy(y[left_idxs]), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_entropy(y[right_idxs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m child_entropy \u001b[39m=\u001b[39m (n_left \u001b[39m/\u001b[39m n) \u001b[39m*\u001b[39m entropy_left \u001b[39m+\u001b[39m (n_right \u001b[39m/\u001b[39m n) \u001b[39m*\u001b[39m entropy_right\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m information_gain \u001b[39m=\u001b[39m parent_entropy \u001b[39m-\u001b[39m child_entropy\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 18\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m hist \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mbincount(y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m ps \u001b[39m=\u001b[39m hist \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X22sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum([p \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog2(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m ps \u001b[39mif\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_evaluate_models(bank_train, bank_test, bank_groups_train, bank_groups_test, \"Bank Marketing\")\n",
    "print(results)\n",
    "#train_and_evaluate_models(wage_train, wage_test, wage_groups_train, wage_groups_test, \"Wage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_models(wage_train, wage_test, wage_groups_train, wage_groups_test, \"Wage\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_and_evaluate_models(compas_train, compas_test, compas_groups_train, compas_groups_test, \u001b[39m\"\u001b[39;49m\u001b[39mCOMPAS\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# # Train and evaluate BaselineRandomForestClassifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# baseline_clf = BaselineRandomForestClassifier(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#     n_estimators=10,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Train and evaluate PrePruneRandomForestClassifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m pre_prune_clf \u001b[39m=\u001b[39m PrePruneRandomForestClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     fairness_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m pre_prune_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train, groups_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m predictions \u001b[39m=\u001b[39m pre_prune_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m results\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPrePruneRandomForestClassifier\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m: dataset_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39maverage_odds_diff\u001b[39m\u001b[39m'\u001b[39m: average_odds_diff(groups_test, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m groups_test, predictions, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m })\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m group_sample \u001b[39m=\u001b[39m groups[idxs]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m tree \u001b[39m=\u001b[39m PrePruneDecisionTreeClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m     min_samples_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m     fairness_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfairness_weight\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_sample, y_sample, group_sample)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(groups, pd\u001b[39m.\u001b[39mSeries):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     groups \u001b[39m=\u001b[39m groups\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X, y, groups, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "    \u001b[0;31m[... skipping similar frames: PrePruneDecisionTreeClassifier._grow_tree at line 80 (4 times)]\u001b[0m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m (depth \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39mor\u001b[39;00m num_samples \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_best_split(X, y, groups)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m best_split:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m thresholds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(X[:, feature_idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m thresholds:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     gain, fairness_deviation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_information_gain(X, y, groups, feature_idx, threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     fairness_penalty \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfairness_weight \u001b[39m*\u001b[39m fairness_deviation\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39m#print(f\"fairness pen: {fairness_penalty}, fairness deviation: {fairness_deviation}\")\u001b[39;00m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m y_pred_right \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull_like(y[right_idxs], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y[right_idxs]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Calculate fairness deviations safely\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m fairness_deviation_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_fairness_deviation(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     group_a_left, group_b_left, y_pred_left, y[left_idxs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m fairness_deviation_right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calculate_fairness_deviation(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     group_a_right, group_b_right, y_pred_right, y[right_idxs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Average the fairness deviations\u001b[39;00m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m \u001b[39m\u001b[39m\"\"\"Safe calculation of fairness deviation with error handling\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# NOTE: the odds diff and equal opportunity diff are 0 a lot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m  deviation \u001b[39m=\u001b[39m  \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m      [\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m          np\u001b[39m.\u001b[39mabs(average_odds_diff(group_a, group_b, y_pred, y_true)\u001b[39m+\u001b[39m\u001b[39m1e-6\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m          np\u001b[39m.\u001b[39mabs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)\u001b[39m+\u001b[39m\u001b[39m1e-6\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m      ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m  )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m  \u001b[39mreturn\u001b[39;00m deviation\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/holisticai/bias/metrics/_classification.py:710\u001b[0m, in \u001b[0;36maverage_odds_diff\u001b[0;34m(group_a, group_b, y_pred, y_true)\u001b[0m\n\u001b[1;32m    705\u001b[0m group_a, group_b, y_pred, y_true \u001b[39m=\u001b[39m _classification_checks(group_a, group_b, y_pred, y_true)\n\u001b[1;32m    707\u001b[0m \u001b[39m# Compute AOD\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\n\u001b[1;32m    709\u001b[0m     equal_opportunity_diff(group_a, group_b, y_pred, y_true)\n\u001b[0;32m--> 710\u001b[0m     \u001b[39m+\u001b[39m false_positive_rate_diff(group_a, group_b, y_pred, y_true)\n\u001b[1;32m    711\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/holisticai/bias/metrics/_classification.py:549\u001b[0m, in \u001b[0;36mfalse_positive_rate_diff\u001b[0;34m(group_a, group_b, y_pred, y_true)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39m# Calculate false positive rates\u001b[39;00m\n\u001b[1;32m    548\u001b[0m fpr_a \u001b[39m=\u001b[39m confusion_matrix(y_true[group_a \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m], y_pred[group_a \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m], normalize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m, labels\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 549\u001b[0m fpr_b \u001b[39m=\u001b[39m confusion_matrix(y_true[group_b \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m], y_pred[group_b \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m], normalize\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrue\u001b[39;49m\u001b[39m\"\u001b[39;49m, labels\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m])[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m fpr_a \u001b[39m-\u001b[39m fpr_b\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/metrics/_classification.py:376\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m need_index_conversion:\n\u001b[1;32m    375\u001b[0m     label_to_ind \u001b[39m=\u001b[39m {y: x \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels)}\n\u001b[0;32m--> 376\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([label_to_ind\u001b[39m.\u001b[39;49mget(x, n_labels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y_pred])\n\u001b[1;32m    377\u001b[0m     y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([label_to_ind\u001b[39m.\u001b[39mget(x, n_labels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y_true])\n\u001b[1;32m    379\u001b[0m \u001b[39m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"\\nModel: {result['model']} | Dataset: {result['dataset']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Equal Opportunity Diff: {result['equal_opportunity_diff']:.4f}\")\n",
    "    print(f\"Average Odds Diff: {result['average_odds_diff']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holistic-hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
