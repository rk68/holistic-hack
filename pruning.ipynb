{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install holisticai scikit-learn pandas numpy matplotlib seaborn jax -q\n",
    "\n",
    "from holisticai.datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from holisticai.bias.metrics import average_odds_diff, equal_opportunity_diff\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "train = split_dataset['train']\n",
    "test = split_dataset['test']\n",
    "\n",
    "bank_dataset = load_dataset(\"bank_marketing\", protected_attribute=\"marital\")\n",
    "split_dataset2 = bank_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "train2 = split_dataset2['train']\n",
    "test2 = split_dataset2['test']\n",
    "\n",
    "wage_dataset = load_dataset(\"mw_small\", protected_attribute=\"race\")\n",
    "split_dataset3 = wage_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "train3 = split_dataset3['train']\n",
    "test3 = split_dataset3['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Pruning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m \u001b[39m# Create and fit the model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m pre_prune_clf \u001b[39m=\u001b[39m PrePruneRandomForestClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m     fairness_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m pre_prune_clf\u001b[39m.\u001b[39;49mfit(X, y, groups)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m predictions \u001b[39m=\u001b[39m pre_prune_clf\u001b[39m.\u001b[39mpredict(test[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m group_sample \u001b[39m=\u001b[39m groups[idxs]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m tree \u001b[39m=\u001b[39m PrePruneDecisionTreeClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m     min_samples_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m     fairness_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfairness_weight\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_sample, y_sample, group_sample)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(groups, pd\u001b[39m.\u001b[39mSeries):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     groups \u001b[39m=\u001b[39m groups\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X, y, groups, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m (depth \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39mor\u001b[39;00m num_samples \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_best_split(X, y, groups)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m best_split:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m thresholds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(X[:, feature_idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m thresholds:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     gain, fairness_deviation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_information_gain(X, y, groups, feature_idx, threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     fairness_penalty \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfairness_weight \u001b[39m*\u001b[39m fairness_deviation\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39m#print(f\"fairness pen: {fairness_penalty}, fairness deviation: {fairness_deviation}\")\u001b[39;00m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Calculate fairness deviations safely\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m fairness_deviation_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calculate_fairness_deviation(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     group_a_left, group_b_left, y_pred_left, y[left_idxs])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m fairness_deviation_right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_fairness_deviation(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     group_a_right, group_b_right, y_pred_right, y[right_idxs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Average the fairness deviations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m fairness_deviation \u001b[39m=\u001b[39m (fairness_deviation_left \u001b[39m+\u001b[39m fairness_deviation_right) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m \u001b[39m\u001b[39m\"\"\"Safe calculation of fairness deviation with error handling\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# NOTE: the odds diff and equal opportunity diff are 0 a lot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m  deviation \u001b[39m=\u001b[39m  \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m      [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m          np\u001b[39m.\u001b[39mabs(average_odds_diff(group_a, group_b, y_pred, y_true)\u001b[39m+\u001b[39m\u001b[39m1e-6\u001b[39m),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m          np\u001b[39m.\u001b[39mabs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)\u001b[39m+\u001b[39m\u001b[39m1e-6\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m      ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m  )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m  \u001b[39mreturn\u001b[39;00m deviation\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/holisticai/bias/metrics/_classification.py:496\u001b[0m, in \u001b[0;36mequal_opportunity_diff\u001b[0;34m(group_a, group_b, y_pred, y_true)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39m# Calculate true positive rates\u001b[39;00m\n\u001b[1;32m    495\u001b[0m tpr_a \u001b[39m=\u001b[39m confusion_matrix(y_true[group_a \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m], y_pred[group_a \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m], normalize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m, labels\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m])[\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 496\u001b[0m tpr_b \u001b[39m=\u001b[39m confusion_matrix(y_true[group_b \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m], y_pred[group_b \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m], normalize\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrue\u001b[39;49m\u001b[39m\"\u001b[39;49m, labels\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m])[\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m    498\u001b[0m \u001b[39mreturn\u001b[39;00m tpr_a \u001b[39m-\u001b[39m tpr_b\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/metrics/_classification.py:363\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(sample_weight)\n\u001b[0;32m--> 363\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    365\u001b[0m n_labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize\n\u001b[1;32m    366\u001b[0m \u001b[39m# If labels are not consecutive integers starting from zero, then\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m# y_true and y_pred must be converted into index form\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/utils/validation.py:454\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[1;32m    437\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \n\u001b[1;32m    439\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    455\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSingleton array \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m cannot be considered a valid collection.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m x\n\u001b[1;32m    384\u001b[0m         )\n\u001b[1;32m    385\u001b[0m     \u001b[39m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[39m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], numbers\u001b[39m.\u001b[39;49mIntegral):\n\u001b[1;32m    388\u001b[0m         \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    390\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "# from holisticai.bias.metrics import average_odds_diff\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "class PrePruneDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, fairness_weight=0.5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.fairness_weight = fairness_weight\n",
    "        self.tree_ = None\n",
    "\n",
    "    def _calculate_fairness_deviation(self, group_a, group_b, y_pred, y_true):\n",
    "        \"\"\"Safe calculation of fairness deviation with error handling\"\"\"\n",
    "\n",
    "       # NOTE: the odds diff and equal opportunity diff are 0 a lot\n",
    "        deviation =  1.0 - np.mean(\n",
    "            [\n",
    "                np.abs(average_odds_diff(group_a, group_b, y_pred, y_true)+1e-6),\n",
    "                np.abs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)+1e-6)\n",
    "            ]\n",
    "        )\n",
    "        return deviation\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, groups, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0, float('inf')\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        # Calculate fairness metrics safely\n",
    "        group_a_left = groups[left_idxs] == 0\n",
    "        group_b_left = groups[left_idxs] == 1\n",
    "        group_a_right = groups[right_idxs] == 0\n",
    "        group_b_right = groups[right_idxs] == 1\n",
    "\n",
    "        # Use the most common label in each split as the prediction\n",
    "        y_pred_left = np.full_like(y[left_idxs], self._most_common_label(y[left_idxs]))\n",
    "        y_pred_right = np.full_like(y[right_idxs], self._most_common_label(y[right_idxs]))\n",
    "\n",
    "        # Calculate fairness deviations safely\n",
    "        fairness_deviation_left = self._calculate_fairness_deviation(\n",
    "            group_a_left, group_b_left, y_pred_left, y[left_idxs])\n",
    "        fairness_deviation_right = self._calculate_fairness_deviation(\n",
    "            group_a_right, group_b_right, y_pred_right, y[right_idxs])\n",
    "\n",
    "        # Average the fairness deviations\n",
    "        fairness_deviation = (fairness_deviation_left + fairness_deviation_right) / 2\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain, fairness_deviation\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "        self.tree_ = self._grow_tree(X, y, groups, depth=0)\n",
    "\n",
    "    # Rest of the CustomDecisionTreeClassifier methods remain the same...\n",
    "    def _grow_tree(self, X, y, groups, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        if (depth >= self.max_depth or num_samples < self.min_samples_split or len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        best_split = self._find_best_split(X, y, groups)\n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, best_split['feature_idx']], best_split['threshold'])\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth + 1)\n",
    "\n",
    "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def _find_best_split(self, X, y, groups):\n",
    "        num_samples, num_features = X.shape\n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain, fairness_deviation = self._calculate_information_gain(X, y, groups, feature_idx, threshold)\n",
    "                \n",
    "                fairness_penalty = self.fairness_weight * fairness_deviation\n",
    "                #print(f\"fairness pen: {fairness_penalty}, fairness deviation: {fairness_deviation}\")\n",
    "                adjusted_gain = gain - fairness_penalty\n",
    "\n",
    "                if adjusted_gain > best_gain:\n",
    "                    best_gain = adjusted_gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain != -float('inf') else None\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return np.array([self._traverse_tree(x, self.tree_) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "\n",
    "class PrePruneRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, fairness_weight=0.5, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.fairness_weight = fairness_weight\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            group_sample = groups[idxs]\n",
    "\n",
    "            tree = PrePruneDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                fairness_weight=self.fairness_weight\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample, group_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "    \n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "groups = np.where(train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "# Create and fit the model\n",
    "pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    fairness_weight=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "pre_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pre_prune_clf.predict(test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6550607287449393\n",
      "equal opportunity diff -0.00521607691545245\n",
      "average odds diff -0.0657650549769987\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. why is fairness deviation = 0\n",
    "# 2. Add terms for race and gender bias (?) + model needs to trade off\n",
    "# 3. Fix hyperparmaeter optimization to get the best model + scores]\n",
    "\n",
    "\n",
    "# Limitation: protected characterstic needs to be binary \n",
    "# Extension: pairwise bias and how to mitigate that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Pruning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from holisticai.bias.metrics import average_odds_diff\n",
    "\n",
    "class PostPruneDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, verbose=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        self.tree_ = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        if (depth >= self.max_depth or num_samples < self.min_samples_split or len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        \n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, best_split['feature_idx']], best_split['threshold'])\n",
    "\n",
    "        # If either split is empty, return the most common label\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
    "\n",
    "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._calculate_information_gain(X, y, feature_idx, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain != -float('inf') else None\n",
    "    \n",
    "\n",
    "    def _calculate_fairness_deviation(self, group_a, group_b, y_pred, y_true):\n",
    "        \"\"\"Safe calculation of fairness deviation with error handling\"\"\"\n",
    "\n",
    "       # NOTE: the odds diff and equal opportunity diff are 0 a lot\n",
    "        deviation =  1.0 - np.mean(\n",
    "            [\n",
    "                np.abs(average_odds_diff(group_a, group_b, y_pred, y_true)+1e-6),\n",
    "                np.abs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)+1e-6)\n",
    "            ]\n",
    "        )\n",
    "        return deviation\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0  # Default to label 0 if y is empty\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return np.array([self._traverse_tree(x, self.tree_) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "\n",
    "    def prune_for_fairness_and_accuracy(self, X, y, groups):\n",
    "        \"\"\"\n",
    "        Post-training pruning to improve fairness and maintain accuracy.\n",
    "        Start pruning from the leaves to avoid removing too much of the tree at once.\n",
    "        \"\"\"\n",
    "        group_a = np.where(groups == 1, 1, 0)\n",
    "        group_b = np.where(groups == 0, 1, 0)\n",
    "        initial_leaves_count = self._count_leaves(self.tree_)\n",
    "        initial_fairness = self._calculate_fairness_deviation(group_a, group_b, self.predict(X), y)#1 - average_odds_diff(group_a, group_b, self.predict(X), y)\n",
    "        initial_accuracy = accuracy_score(y, self.predict(X))\n",
    "\n",
    "        self._prune_tree(self.tree_, X, y, groups)\n",
    "\n",
    "        final_leaves_count = self._count_leaves(self.tree_)\n",
    "        final_fairness = self._calculate_fairness_deviation(group_a, group_b, self.predict(X), y) #1 - average_odds_diff(groups, groups, self.predict(X), y)\n",
    "        final_accuracy = accuracy_score(y, self.predict(X))\n",
    "        if self.verbose == True:\n",
    "            print(f\"Initial number of leaves: {initial_leaves_count}\")\n",
    "            print(f\"Final number of leaves: {final_leaves_count}\")\n",
    "            print(f\"Difference in number of leaves: {initial_leaves_count - final_leaves_count}\")\n",
    "            print(f\"Fairness before pruning: {initial_fairness}\")\n",
    "            print(f\"Fairness after pruning: {final_fairness}\")\n",
    "            print(f\"Difference in fairness: {final_fairness - initial_fairness}\")\n",
    "            print(f\"Accuracy before pruning: {initial_accuracy}\")\n",
    "            print(f\"Accuracy after pruning: {final_accuracy}\")\n",
    "            print(f\"Difference in accuracy: {final_accuracy - initial_accuracy}\")\n",
    "\n",
    "    def _prune_tree(self, node, X, y, groups):\n",
    "        if 'label' in node:\n",
    "            return\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X[:, node['feature_idx']], node['threshold'])\n",
    "        \n",
    "        # Check if split produces empty nodes\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            node.clear()\n",
    "            node['label'] = self._most_common_label(y)\n",
    "            return\n",
    "\n",
    "        # Recursively prune left and right subtrees first (bottom-up approach)\n",
    "        self._prune_tree(node['left'], X[left_idxs], y[left_idxs], groups[left_idxs])\n",
    "        self._prune_tree(node['right'], X[right_idxs], y[right_idxs], groups[right_idxs])\n",
    "\n",
    "        # Only consider pruning if both children are leaves\n",
    "        if 'label' not in node['left'] or 'label' not in node['right']:\n",
    "            return\n",
    "\n",
    "        # Calculate metrics before pruning\n",
    "        group_a = np.where(groups == 1, 1, 0)\n",
    "        group_b = np.where(groups == 0, 1, 0)\n",
    "\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy_before = accuracy_score(y, y_pred)\n",
    "\n",
    "        fairness_before = self._calculate_fairness_deviation(group_a, group_b, y_pred, y)#1 - average_odds_diff(group_a, group_b, y_pred, y)\n",
    "\n",
    "\n",
    "        # Temporarily prune the node\n",
    "        original_node = node.copy()\n",
    "        node.clear()\n",
    "        node['label'] = self._most_common_label(y)\n",
    "\n",
    "        # Calculate metrics after pruning\n",
    "        y_pred_pruned = self.predict(X)\n",
    "        accuracy_after = accuracy_score(y, y_pred_pruned)\n",
    "        fairness_after = self._calculate_fairness_deviation(group_a, group_b, y_pred_pruned, y)#1 - average_odds_diff(group_a, group_b, y_pred_pruned, y)\n",
    "\n",
    "        # Define minimum acceptable changes\n",
    "        MIN_ACCURACY_DROP = 0.01  # Allow maximum 2% accuracy drop\n",
    "        MIN_FAIRNESS_IMPROVEMENT = 0.03  # Require at least 5% fairness improvement\n",
    "\n",
    "        # Restore the node if:\n",
    "        # 1. Accuracy drops more than threshold OR\n",
    "        # 2. Fairness doesn't improve enough\n",
    "        if (accuracy_before - accuracy_after > MIN_ACCURACY_DROP or \n",
    "            fairness_after - fairness_before < MIN_FAIRNESS_IMPROVEMENT):\n",
    "            node.clear()\n",
    "            node.update(original_node)\n",
    "        \n",
    "    def _count_leaves(self, node):\n",
    "        if 'label' in node:\n",
    "            return 1\n",
    "        return self._count_leaves(node['left']) + self._count_leaves(node['right'])\n",
    "\n",
    "\n",
    "class PostPruneRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, groups):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(groups, pd.Series):\n",
    "            groups = groups.values\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            group_sample = groups[idxs]\n",
    "\n",
    "            tree = PostPruneDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            tree.prune_for_fairness_and_accuracy(X_sample, y_sample, group_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "\n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "groups = np.where(train['p_attrs'][\"sex\"].to_numpy() == \"Male\", 1, 0)\n",
    "\n",
    "# Create and fit the model\n",
    "post_prune_clf = PostPruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    random_state=42\n",
    ")\n",
    "post_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = post_prune_clf.predict(test['X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6510121457489878\n",
      "equal opportunity diff -0.04561899098027555\n",
      "average odds diff -0.09601394830413507\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m \u001b[39m# Create and fit the model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m baseline_clf \u001b[39m=\u001b[39m BaselineRandomForestClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m baseline_clf\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m predictions \u001b[39m=\u001b[39m baseline_clf\u001b[39m.\u001b[39mpredict(test[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m X_sample, y_sample \u001b[39m=\u001b[39m X[idxs], y[idxs]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m tree \u001b[39m=\u001b[39m BaselineDecisionTreeClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     min_samples_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_sample, y_sample)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(y, pd\u001b[39m.\u001b[39mSeries):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X, y, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "    \u001b[0;31m[... skipping similar frames: BaselineDecisionTreeClassifier._grow_tree at line 30 (12 times)]\u001b[0m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[left_idxs], y[left_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[right_idxs], y[right_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m num_samples, num_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m (depth \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39mor\u001b[39;00m num_samples \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_best_split(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m best_split:\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_most_common_label\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X12sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Counter(y)\u001b[39m.\u001b[39;49mmost_common(\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "class BaselineDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if len(y) == 0:\n",
    "            raise ValueError(\"Cannot train on empty dataset\")\n",
    "        self.tree_ = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        \n",
    "        # Check for empty arrays\n",
    "        if num_samples == 0:\n",
    "            return {'label': 0}  # Default label for empty node\n",
    "            \n",
    "        if (depth >= self.max_depth or \n",
    "            num_samples < self.min_samples_split or \n",
    "            len(set(y)) == 1):\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if not best_split:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        feature_idx = best_split['feature_idx']\n",
    "        threshold = best_split['threshold']\n",
    "        \n",
    "        # Get the split indices\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        \n",
    "        # Check if split is valid\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return {'label': self._most_common_label(y)}\n",
    "\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'feature_idx': feature_idx,\n",
    "            'threshold': threshold,\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree\n",
    "        }\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        if num_samples < 2:  # Need at least 2 samples to split\n",
    "            return None\n",
    "            \n",
    "        best_split = {}\n",
    "        best_gain = -float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._calculate_information_gain(X, y, feature_idx, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold}\n",
    "\n",
    "        return best_split if best_gain > -float('inf') else None\n",
    "\n",
    "    def _calculate_information_gain(self, X, y, feature_idx, threshold):\n",
    "        left_idxs, right_idxs = self._split(X[:, feature_idx], threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return -float('inf')\n",
    "\n",
    "        parent_entropy = self._entropy(y)\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, feature_column, threshold):\n",
    "        left_idxs = np.argwhere(feature_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(feature_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0  # Default label for empty array\n",
    "        counter = Counter(y)\n",
    "        if not counter:\n",
    "            return 0  # Default label for empty counter\n",
    "        return counter.most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if not self.tree_:\n",
    "            raise ValueError(\"Tree not fitted. Call fit() first.\")\n",
    "        return np.array([self._traverse_tree(x, self.tree_) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        if x[node['feature_idx']] <= node['threshold']:\n",
    "            return self._traverse_tree(x, node['left'])\n",
    "        return self._traverse_tree(x, node['right'])\n",
    "\n",
    "\n",
    "class BaselineRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if len(y) == 0:\n",
    "            raise ValueError(\"Cannot train on empty dataset\")\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "\n",
    "            tree = BaselineDecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.round(tree_preds.mean(axis=0)).astype(int)\n",
    "\n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "\n",
    "# Create and fit the model\n",
    "baseline_clf = BaselineRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    random_state=42\n",
    ")\n",
    "baseline_clf.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = baseline_clf.predict(test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "\n",
    "compas_dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "compas_split_dataset = compas_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "compas_train = compas_split_dataset['train']\n",
    "compas_test = compas_split_dataset['test']\n",
    "\n",
    "bank_dataset = load_dataset(\"bank_marketing\", protected_attribute=\"marital\")\n",
    "bank_split_dataset = bank_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "bank_train = bank_split_dataset['train']\n",
    "bank_test = bank_split_dataset['test']\n",
    "\n",
    "wage_dataset = load_dataset(\"mw_small\", protected_attribute=\"race\")\n",
    "wage_split_dataset = wage_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "wage_train = wage_split_dataset['train']\n",
    "wage_test = wage_split_dataset['test']\n",
    "\n",
    "compas_groups = np.where(compas_train['p_attrs']['sex'].to_numpy() == 'Male', 1, 0)\n",
    "bank_groups = np.where(bank_train['p_attrs']['marital'].to_numpy() == 1, 1, 0)\n",
    "wage_groups = np.where(wage_train['p_attrs'][\"race\"].to_numpy() == \"White\", 1, 0)\n",
    "\n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "\n",
    "# Create and fit the model\n",
    "baseline_clf = BaselineRandomForestClassifier(\n",
    "    n_estimators=3,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "baseline_clf.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = baseline_clf.predict(test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "\n",
    "\n",
    "pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=16,\n",
    "    fairness_weight=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "pre_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pre_prune_clf.predict(test['X'])\n",
    "\n",
    "print(\"accuracy\", np.count_nonzero(predictions == test['y'])/len(test['y']))\n",
    "print(\"equal opportunity diff\", equal_opportunity_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "print(\"average odds diff\", average_odds_diff(test['group_a'], test['group_b'], predictions, test['y']))\n",
    "\n",
    "# Example usage\n",
    "X = train['X']\n",
    "y = train['y']\n",
    "\n",
    "# Create and fit the model\n",
    "post_prune_clf = PostPruneRandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=50,\n",
    "    random_state=42\n",
    ")\n",
    "post_prune_clf.fit(X, y, groups)\n",
    "\n",
    "# Make predictions\n",
    "predictions = post_prune_clf.predict(test['X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "compas_dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "compas_split_dataset = compas_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "compas_train = compas_split_dataset['train']\n",
    "compas_test = compas_split_dataset['test']\n",
    "\n",
    "bank_dataset = load_dataset(\"bank_marketing\", protected_attribute=\"marital\")\n",
    "bank_split_dataset = bank_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "bank_train = bank_split_dataset['train']\n",
    "bank_test = bank_split_dataset['test']\n",
    "\n",
    "wage_dataset = load_dataset(\"mw_small\", protected_attribute=\"race\")\n",
    "wage_split_dataset = wage_dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "wage_train = wage_split_dataset['train']\n",
    "wage_test = wage_split_dataset['test']\n",
    "\n",
    "# Define groups for each dataset\n",
    "compas_groups_train = np.where(compas_train['p_attrs']['sex'].to_numpy() == 'Male', 1, 0)\n",
    "compas_groups_test = np.where(compas_test['p_attrs']['sex'].to_numpy() == 'Male', 1, 0)\n",
    "\n",
    "bank_groups_train = np.where(bank_train['p_attrs']['marital'].to_numpy() == 1, 1, 0)\n",
    "bank_groups_test = np.where(bank_test['p_attrs']['marital'].to_numpy() == 1, 1, 0)\n",
    "\n",
    "wage_groups_train = np.where(wage_train['p_attrs']['race'].to_numpy() == \"White\", 1, 0)\n",
    "wage_groups_test = np.where(wage_test['p_attrs']['race'].to_numpy() == \"White\", 1, 0)\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = []\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(train, test, groups_train, groups_test, dataset_name):\n",
    "    X_train, y_train = train['X'], train['y']\n",
    "    X_test, y_test = test['X'], test['y']\n",
    "    \n",
    "    # # Train and evaluate BaselineRandomForestClassifier\n",
    "    # baseline_clf = BaselineRandomForestClassifier(\n",
    "    #     n_estimators=10,\n",
    "    #     max_depth=16,\n",
    "    #     random_state=42\n",
    "    # )\n",
    "    # baseline_clf.fit(X_train, y_train)\n",
    "    # predictions = baseline_clf.predict(X_test)\n",
    "    \n",
    "    # results.append({\n",
    "    #     'model': 'BaselineRandomForestClassifier',\n",
    "    #     'dataset': dataset_name,\n",
    "    #     'accuracy': np.count_nonzero(predictions == y_test) / len(y_test),\n",
    "    #     'equal_opportunity_diff': equal_opportunity_diff(groups_test, 1 - groups_test, predictions, y_test),\n",
    "    #     'average_odds_diff': average_odds_diff(groups_test, 1 - groups_test, predictions, y_test)\n",
    "    # })\n",
    "    \n",
    "    # Train and evaluate PrePruneRandomForestClassifier\n",
    "    pre_prune_clf = PrePruneRandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        max_depth=16,\n",
    "        fairness_weight=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    pre_prune_clf.fit(X_train, y_train, groups_train)\n",
    "    predictions = pre_prune_clf.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        'model': 'PrePruneRandomForestClassifier',\n",
    "        'dataset': dataset_name,\n",
    "        'accuracy': np.count_nonzero(predictions == y_test) / len(y_test),\n",
    "        'equal_opportunity_diff': equal_opportunity_diff(groups_test, 1 - groups_test, predictions, y_test),\n",
    "        'average_odds_diff': average_odds_diff(groups_test, 1 - groups_test, predictions, y_test)\n",
    "    })\n",
    "    \n",
    "    # Train and evaluate PostPruneRandomForestClassifier\n",
    "    post_prune_clf = PostPruneRandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        max_depth=16,\n",
    "        random_state=42\n",
    "    )\n",
    "    post_prune_clf.fit(X_train, y_train, groups_train)\n",
    "    predictions = post_prune_clf.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        'model': 'PostPruneRandomForestClassifier',\n",
    "        'dataset': dataset_name,\n",
    "        'accuracy': np.count_nonzero(predictions == y_test) / len(y_test),\n",
    "        'equal_opportunity_diff': equal_opportunity_diff(groups_test, 1 - groups_test, predictions, y_test),\n",
    "        'average_odds_diff': average_odds_diff(groups_test, 1 - groups_test, predictions, y_test)\n",
    "    })\n",
    "\n",
    "# Train and evaluate models for each dataset\n",
    "train_and_evaluate_models(compas_train, compas_test, compas_groups_train, compas_groups_test, \"COMPAS\")\n",
    "#train_and_evaluate_models(bank_train, bank_test, bank_groups_train, bank_groups_test, \"Bank Marketing\")\n",
    "#train_and_evaluate_models(wage_train, wage_test, wage_groups_train, wage_groups_test, \"Wage\")\n",
    "\n",
    "# Print all results at the end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_models(bank_train, bank_test, bank_groups_train, bank_groups_test, \"Bank Marketing\")\n",
    "print(results)\n",
    "#train_and_evaluate_models(wage_train, wage_test, wage_groups_train, wage_groups_test, \"Wage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_models(wage_train, wage_test, wage_groups_train, wage_groups_test, \"Wage\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_and_evaluate_models(compas_train, compas_test, compas_groups_train, compas_groups_test, \u001b[39m\"\u001b[39;49m\u001b[39mCOMPAS\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# # Train and evaluate BaselineRandomForestClassifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# baseline_clf = BaselineRandomForestClassifier(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#     n_estimators=10,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Train and evaluate PrePruneRandomForestClassifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m pre_prune_clf \u001b[39m=\u001b[39m PrePruneRandomForestClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     fairness_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m pre_prune_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train, groups_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m predictions \u001b[39m=\u001b[39m pre_prune_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m results\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPrePruneRandomForestClassifier\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m: dataset_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39maverage_odds_diff\u001b[39m\u001b[39m'\u001b[39m: average_odds_diff(groups_test, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m groups_test, predictions, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m })\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m group_sample \u001b[39m=\u001b[39m groups[idxs]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m tree \u001b[39m=\u001b[39m PrePruneDecisionTreeClassifier(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m     min_samples_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m     fairness_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfairness_weight\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_sample, y_sample, group_sample)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(groups, pd\u001b[39m.\u001b[39mSeries):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     groups \u001b[39m=\u001b[39m groups\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X, y, groups, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "    \u001b[0;31m[... skipping similar frames: PrePruneDecisionTreeClassifier._grow_tree at line 80 (4 times)]\u001b[0m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m left_idxs, right_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(X[:, best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m]], best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X[left_idxs], y[left_idxs], groups[left_idxs], depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow_tree(X[right_idxs], y[right_idxs], groups[right_idxs], depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mfeature_idx\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: best_split[\u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m: left_subtree, \u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m: right_subtree}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m (depth \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth \u001b[39mor\u001b[39;00m num_samples \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(y)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_best_split(X, y, groups)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m best_split:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y)}\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m thresholds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(X[:, feature_idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m thresholds:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     gain, fairness_deviation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_information_gain(X, y, groups, feature_idx, threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     fairness_penalty \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfairness_weight \u001b[39m*\u001b[39m fairness_deviation\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39m#print(f\"fairness pen: {fairness_penalty}, fairness deviation: {fairness_deviation}\")\u001b[39;00m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m y_pred_right \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull_like(y[right_idxs], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_common_label(y[right_idxs]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Calculate fairness deviations safely\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m fairness_deviation_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_fairness_deviation(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     group_a_left, group_b_left, y_pred_left, y[left_idxs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m fairness_deviation_right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calculate_fairness_deviation(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     group_a_right, group_b_right, y_pred_right, y[right_idxs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Average the fairness deviations\u001b[39;00m\n",
      "\u001b[1;32m/Users/rishi/Documents/holistic-hack/pruning.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m \u001b[39m\u001b[39m\"\"\"Safe calculation of fairness deviation with error handling\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# NOTE: the odds diff and equal opportunity diff are 0 a lot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m  deviation \u001b[39m=\u001b[39m  \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m      [\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m          np\u001b[39m.\u001b[39mabs(average_odds_diff(group_a, group_b, y_pred, y_true)\u001b[39m+\u001b[39m\u001b[39m1e-6\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m          np\u001b[39m.\u001b[39mabs(equal_opportunity_diff(group_a, group_b, y_pred, y_true)\u001b[39m+\u001b[39m\u001b[39m1e-6\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m      ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m  )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rishi/Documents/holistic-hack/pruning.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m  \u001b[39mreturn\u001b[39;00m deviation\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/holisticai/bias/metrics/_classification.py:710\u001b[0m, in \u001b[0;36maverage_odds_diff\u001b[0;34m(group_a, group_b, y_pred, y_true)\u001b[0m\n\u001b[1;32m    705\u001b[0m group_a, group_b, y_pred, y_true \u001b[39m=\u001b[39m _classification_checks(group_a, group_b, y_pred, y_true)\n\u001b[1;32m    707\u001b[0m \u001b[39m# Compute AOD\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\n\u001b[1;32m    709\u001b[0m     equal_opportunity_diff(group_a, group_b, y_pred, y_true)\n\u001b[0;32m--> 710\u001b[0m     \u001b[39m+\u001b[39m false_positive_rate_diff(group_a, group_b, y_pred, y_true)\n\u001b[1;32m    711\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/holisticai/bias/metrics/_classification.py:549\u001b[0m, in \u001b[0;36mfalse_positive_rate_diff\u001b[0;34m(group_a, group_b, y_pred, y_true)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39m# Calculate false positive rates\u001b[39;00m\n\u001b[1;32m    548\u001b[0m fpr_a \u001b[39m=\u001b[39m confusion_matrix(y_true[group_a \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m], y_pred[group_a \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m], normalize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m, labels\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 549\u001b[0m fpr_b \u001b[39m=\u001b[39m confusion_matrix(y_true[group_b \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m], y_pred[group_b \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m], normalize\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrue\u001b[39;49m\u001b[39m\"\u001b[39;49m, labels\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m])[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m fpr_a \u001b[39m-\u001b[39m fpr_b\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/holistic-hack/holistic-hack/lib/python3.12/site-packages/sklearn/metrics/_classification.py:376\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m need_index_conversion:\n\u001b[1;32m    375\u001b[0m     label_to_ind \u001b[39m=\u001b[39m {y: x \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels)}\n\u001b[0;32m--> 376\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([label_to_ind\u001b[39m.\u001b[39;49mget(x, n_labels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y_pred])\n\u001b[1;32m    377\u001b[0m     y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([label_to_ind\u001b[39m.\u001b[39mget(x, n_labels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y_true])\n\u001b[1;32m    379\u001b[0m \u001b[39m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"\\nModel: {result['model']} | Dataset: {result['dataset']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Equal Opportunity Diff: {result['equal_opportunity_diff']:.4f}\")\n",
    "    print(f\"Average Odds Diff: {result['average_odds_diff']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holistic-hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
